---
layout: post
title: A Reading List for Automatic Speech Recognition
tags: ["speech recognition"]
mathjax: true
future: true
---
Here is a list of papers and book chapters for someone who wants to get started with ASR. This has been compiled from the required reading list in Shinji Watanabe's Information Extraction course offered at JHU in Spring 2019.

1. [Automatic speech recognition â€“ a brief history of the technology development](https://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/354_LALI-ASRHistory-final-10-8.pdf). Juang and Rabiner.
2. [An introduction to hidden Markov models](http://ai.stanford.edu/~pabbeel/depth_qual/Rabiner_Juang_hmms.pdf). Rabiner and Juang.
3. GMMs and k-means (Bishop's PRML Section 9.1 and 9.2)
4. Feature extraction for ASR (Jurafsky and Martin 2nd edition Section 9.3)
5. [EM algorithm and its application to parameter estimation for GMM-HMM models](http://imaging.mrc-cbu.cam.ac.uk/methods/BayesianStuff?action=AttachFile&do=get&target=bilmes-em-algorithm.pdf). Jeff Bilmes.
6. [Maximum a Posteriori Estimation for Multivariate Gaussian Mixture Observations of Markov Chains](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=279278). Gauvain and Lee. IEEE Transactions on Speecch and Audio Processing. April 1994.
7. [Tree-based state tying for high accuracy modeling](https://www.aclweb.org/anthology/H94-1062/). Young et al. ACL 1994.
8. [Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.2050&rep=rep1&type=pdf). C. J. Leggetter, P. C. Woodland. Computer speech & language.
9. [Acoustic modeling based on the MDL principle for speech recognition](https://www.isca-speech.org/archive/archive_papers/eurospeech_1997/e97_0099.pdf). Shinoda and Watanabe. Eurospeech 1997.
10. [Linear discriminant analysis for improved LVSCR](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.9729&rep=rep1&type=pdf). Haeb-Umbach, R., & Ney, H. ICASSP 1992.
11. [An empirical study of smoothing techniques for language modeling](http://aclweb.org/anthology/P96-1041). Chen and Goodman. ACL 1996.
12. [DNNs for acoustic modeling in speech recognition](http://ieeexplore.ieee.org/abstract/document/6296526/). Hinton et al. IEEE Signal Processing Magazine.
13. [Front-end factor analysis for speaker verification](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5545402). Dehak et al. IEEE Transactions on Audio, Speech, and Language Processing.
14. [Conversational speech transcription using context-dependent DNNs](https://icml.cc/2012/papers/943.pdf). Yu, Seide, and Li. ICML 2012.
15. [Applying CNNs to hybrid NN-HMM model for speech recognition](http://www.cs.toronto.edu/~asamir/papers/icassp12_cnn.pdf). Abdel-Hamid et al. ICASSP 2012.
16. [LSTM based RNNs for large vocabulary speech recognition](https://arxiv.org/pdf/1402.1128.pdf). Sak et al. Interspeech 2014.
17. [Sequence-discriminative training of DNNs](https://www.danielpovey.com/files/2013_interspeech_dnn.pdf). Vesely et al. Interspeech 2013.
18. [RNN based language model](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf). Mikolov et al. Interspeech 2010.
19. [Speech enhancement with LSTM recurrent neural networks and its application to noise-robust ASR](https://hal.inria.fr/hal-01163493/document). Weninger et al. 
20. [WaveNet: a generative model for raw audio](https://arxiv.org/pdf/1609.03499.pdf). Oord et al.
21. [Sequence to sequence learning with neural networks](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf). Sutskever et al. NIPS 2014.
22. [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf). Graves et al. ICML 2006.
23. [End-to-end attention-based large vocabulary speech recognition](https://arxiv.org/pdf/1508.04395.pdf). Bahdanau et al. ICASSP 2016.
24. [Listen, attend, and spell](https://arxiv.org/pdf/1508.01211.pdf). Chan, Jaitly, Le, and Vinyals.
25. [Joint CTC-attention based end-to-end speech recognition using MTL](https://arxiv.org/pdf/1609.06773.pdf). Kim et al. ICASSP 2017.